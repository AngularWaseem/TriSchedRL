TriSchedRL: A Guarded Deep Reinforcement Learning Framework for SLA Latency and Energy Aware IoT Task Scheduling in Edge Cloud Environments
________________________________________
ğŸš€ TriSchedRL
A Guarded Deep Reinforcement Learning Framework for SLA Latency and Energy-Aware IoT Task Scheduling in Edgeâ€“Cloud Environments
TriSchedRL is a research-driven implementation of a Guarded Deep Reinforcement Learning (DRL) framework designed to optimize SLA latency, energy consumption, and resource utilization for IoT task scheduling across heterogeneous edgeâ€“cloud infrastructures.
This repository contains the complete modular implementation, experimental pipeline, evaluation scripts, and reproducible configurations used in the SCI research paper.
________________________________________
ğŸ“Œ Key Features
âœ… Guarded Deep Reinforcement Learning Scheduler
âœ… SLA-Aware Policy Learning
âœ… Energy and Latency Joint Optimization
âœ… Edgeâ€“Cloud Continuum Simulation
âœ… Modular and Reproducible Research Pipeline
âœ… Ready for Academic Benchmarking and Extensions
________________________________________
ğŸ§  Research Motivation
Modern IoT environments generate heterogeneous workloads requiring real-time processing. Traditional schedulers fail to:
â€¢	Guarantee SLA constraints
â€¢	Adapt to dynamic network states
â€¢	Balance energy vs. latency trade-offs
TriSchedRL introduces:
ğŸ‘‰ Guard Module â€” prevents unsafe scheduling decisions
ğŸ‘‰ Tri-Objective Optimization â€” latency + energy + reliability
ğŸ‘‰ Adaptive RL Policy â€” learns optimal offloading and scheduling behavior
________________________________________
ğŸ—ï¸ System Architecture
The framework consists of the following core modules:
â€¢	Environment Simulator â€“ models edge, fog, and cloud nodes
â€¢	Guard Engine â€“ enforces SLA constraints during RL action selection
â€¢	DRL Agent â€“ policy learning using deep neural networks
â€¢	Scheduler Core â€“ executes decisions and monitors system metrics
â€¢	Evaluation Engine â€“ computes performance indicators
________________________________________
ğŸ“‚ Repository Structure
TriSchedRL/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ workloads/
â”‚   â”œâ”€â”€ configs/
â”‚   â””â”€â”€ synthetic_generator.py
â”‚
â”œâ”€â”€ env/
â”‚   â”œâ”€â”€ edge_cloud_env.py
â”‚   â”œâ”€â”€ resource_model.py
â”‚   â””â”€â”€ sla_constraints.py
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ policy_network.py
â”‚   â”œâ”€â”€ guarded_rl_agent.py
â”‚   â””â”€â”€ replay_buffer.py
â”‚
â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ tri_scheduler.py
â”‚   â””â”€â”€ decision_engine.py
â”‚
â”œâ”€â”€ guard/
â”‚   â”œâ”€â”€ sla_guard.py
â”‚   â””â”€â”€ safety_checker.py
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ hyperparams.yaml
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baseline_comparisons/
â”‚   â””â”€â”€ ablation_studies/
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ figures/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
________________________________________
âš™ï¸ Installation
Step 1 â€” Clone Repository
git clone https://github.com/<your-username>/TriSchedRL.git
cd TriSchedRL
Step 2 â€” Create Environment
conda create -n trischedrl python=3.10
conda activate trischedrl
Step 3 â€” Install Dependencies
pip install -r requirements.txt
________________________________________
â–¶ï¸ Running the Framework
Train the Guarded RL Scheduler
python training/train.py
Evaluate Performance
python training/evaluate.py
________________________________________
ğŸ“Š Evaluation Metrics
The framework evaluates scheduling performance using:
â€¢	SLA Latency Violation Rate
â€¢	Energy Consumption
â€¢	Task Completion Time
â€¢	Throughput
â€¢	Resource Utilization
â€¢	Reward Convergence
________________________________________
ğŸ”¬ Experimental Design
TriSchedRL supports:
âœ” Synthetic IoT workloads
âœ” Edgeâ€“Cloud heterogeneous resources
âœ” Dynamic arrival rates
âœ” Baseline comparison experiments
Baselines may include:
â€¢	Heuristic Scheduling
â€¢	Metaheuristic Optimization
â€¢	Standard DRL Scheduling
________________________________________
ğŸ“ˆ Visualization
Training curves and scheduling results can be visualized using:
python utils/visualization.py
Outputs include:
â€¢	Reward convergence graphs
â€¢	Energy vs Latency trade-offs
â€¢	SLA violation trends
________________________________________
ğŸ§© Extending the Framework
You can extend TriSchedRL by:
â€¢	Adding new RL algorithms (PPO, SAC, DDPG)
â€¢	Integrating federated learning
â€¢	Introducing new SLA constraints
â€¢	Deploying on real edge devices
________________________________________
ğŸ“„ Paper Alignment
This repository corresponds to the SCI research paper:
TriSchedRL: A Guarded Deep Reinforcement Learning Framework for SLA Latency and Energy Aware IoT Task Scheduling in Edge Cloud Environments
________________________________________
ğŸ§ª Reproducibility
To ensure reproducibility:
â€¢	Random seeds are fixed
â€¢	Hyperparameters stored in YAML
â€¢	Experiment logs saved automatically
________________________________________
ğŸ› ï¸ Requirements
Example dependencies:
python>=3.10
torch
numpy
pandas
gymnasium
matplotlib
pyyaml
________________________________________
ğŸ¤ Contribution Guidelines
1.	Fork repository
2.	Create feature branch
3.	Commit changes
4.	Submit pull request
________________________________________
ğŸ“œ License
This project is released under the MIT License.
________________________________________
â­ Citation
If you use this repository in your research, please cite:
TriSchedRL: A Guarded Deep Reinforcement Learning Framework for SLA Latency and Energy Aware IoT Task Scheduling in Edge Cloud Environments

